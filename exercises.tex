% Notes and exercises from Introduction to Real Analysis by DePree and Swartz
% By John Peloquin
\documentclass[letterpaper,12pt]{article}
\usepackage{amsmath,amssymb,amsthm,enumitem,fourier}

\newcommand{\N}{\mathbf{N}}
\newcommand{\Nex}{\overline{\N}}
\newcommand{\R}{\mathbf{R}}
\newcommand{\Rp}{\R_+}
\newcommand{\Rps}{\Rp^*}
\newcommand{\Rex}{\overline{\R}}

\newcommand{\union}{\cup}
\newcommand{\sect}{\cap}
\newcommand{\after}{\circ}

\newcommand{\inv}[1]{#1^{-1}}
\newcommand{\norm}[1]{\lVert{#1}\rVert}

% Theorems
\theoremstyle{plain}
\newtheorem*{prop}{}

\theoremstyle{definition}
\newtheorem*{exer}{Exercise}

\theoremstyle{remark}
\newtheorem*{rmk}{Remark}

% Meta
\title{Notes and exercises from\\\textit{Foundations of Modern Analysis}}
\author{John Peloquin}
\date{}

\begin{document}
\maketitle

\section*{Introduction}
This document contains notes and exercises from~\cite{dieudonne}.

\section*{Chapter~IV}
\subsection*{Section~3}
\begin{rmk}
In the proof of~(4.3.1), intuitively we know that \(f=\log_a\). Recall by the density of the rationals in the reals (2.2.16) that \emph{a real number is the supremum of the set of rationals less than it}. Therefore \(\log_a x\)~is just the supremum of the set of rationals~\(m/n\) with \(m/n\le\log_a x\), or equivalently \(a^{m/n}\le x\), or equivalently \(a^m\le x^n\); that is, \(\log_a x=\sup A_x\). Since neither \(\log_a x\) nor~\(a^{m/n}\) are defined yet, but \(a^m\)~and~\(x^n\) are, it is natural to show that \(f(x)=\sup A_x\) for uniqueness.

For existence, we know the set~\(A_x\) is well defined. Fix \(k\ge 1\) and choose~\(p,q\) by~(4.3.1.1) with \(a^p\le x^k\le a^q\). Then \(p/k\in A_x\), so \(A_x\)~is nonempty. If \(m/n\in A_x\) (\(n\ge 1\)), then \(a^m\le x^n\), so \(a^{mk}\le x^{nk}\le a^{qn}\), so \(mk\le qn\), and \(m/n\le q/k\); that is, \(A_x\)~is bounded above by~\(q/k\). Therefore \(f(x)=\sup A_x\)~is defined, and \(p/k\le f(x)\le q/k\). Taking \(q=p+1\) yields \(p/k\le f(x)\le(p+1)/k\), which is used in the proof that \(f(xy)=f(x)+f(y)\). Taking \(x=a\) and \(k=p=q=1\) yields \(f(a)=1\).


\end{rmk}

\noindent We provide an alternative proof of~(4.3.7):
\begin{prop}[4.3.7]
Any continuous mapping~\(g\) of~~\(\Rps\) into itself such that \(g(xy)=g(x)g(y)\) has the form \(x\mapsto x^a\), with \(a\in\R\).
\end{prop}
\begin{proof}
If \(b>1\), then \(f=\log_b\after g:\Rps\to\R\) is continuous and
\[f(xy)=\log_b g(xy)=\log_b[g(x)g(y)]=\log_b g(x)+\log_b g(y)=f(x)+f(y)\]
If \(g\ne1\), there is \(x>0\) with \(g(x)>1\) (if \(g(x)<1\), then \(g(\inv{x})=\inv{g(x)}>1\)), so \(y_n=g(x^n)=g(x)^n\to\infty\) as \(n\to\infty\) and \(y_n\to 0\) as \(n\to-\infty\). It follows from (3.19.1) and~(3.19.7) that \(g\)~is surjective, so there is \(c>0\) with \(c\ne 1\) such that \(g(c)=b\) and hence \(f(c)=1\). By~(4.3.2), \(f=\log_c\), so
\[g(x)=b^{\log_c x}=b^{a\log_b x}=x^a\]
where \(a=\log_c b\), by (4.3.3) and~(4.3.4).
\end{proof}
\begin{rmk}
This proof is longer than Dieudonn\'e's, but avoids direct use of~(4.1.3), which is already used in the proof of~(4.3.2).
\end{rmk}

\subsection*{Section~5}
\begin{rmk}
In the proof of the Tietze-Urysohn extension theorem~(4.5.1), the idea behind the formula defining~\(g(x)\) for \(x\in E-A\) is roughly: \emph{for \(x\)~very near the boundary (frontier) of~\(A\), take the limit of~\(f(y)\) as \(y\in A\) approaches points near~\(x\)}:
\[g(x)=\inf_{y\in A}\left[f(y)\frac{d(x,y)}{d(x,A)}\right]\qquad(x\in E-A)\]
Write \(\rho_x(y)=d(x,y)/d(x,A)\). Since \(1\le f(y)\le 2\) by the reduction, \(\rho_x(y)\ge 1\), \(\rho_x(y)>2\) for \(y\)~sufficiently far from~\(x\), and \(\rho_x(y)\to 1\) as \(y\to x\), it follows that \(\inf_{y\in A}f(y)\rho_x(y)\) reflects values of~\(f(y)\) at \(y\)~nearest to~\(x\). This ensures continuity of~\(g\) on the boundary of~\(A\). Since \(g\)~is also continuous in the interior of~\(A\) (by continuity of~\(f\)), and in the exterior of~\(A\) (by continuity of the metric~\(d\)), \(g\)~is continuous on~\(E\).
\end{rmk}

\section*{Chapter~V}
\subsection*{Section~2}
\begin{rmk}
(5.2.4)~is an associativity property for convergent series. For \emph{absolutely} convergent series, (5.3.6)~is a stronger associativity property. For example, if \(\sum_{n=0}^{\infty}x_n\) is absolutely convergent, then it follows from the remark below~(5.3.6), but not from~(5.2.4), that \(\sum_{n=0}^{\infty}x_n=\sum_{n=0}^{\infty}x_{2n}+\sum_{n=0}^{\infty}x_{2n+1}\).
\end{rmk}

\subsection*{Section~3}
\begin{rmk}
In the proof of~(5.3.2), to see how the inequality \(\norm{\sum_{n=0}^{\infty}x_n}\le\sum_{n=0}^{\infty}\norm{x_n}\) follows from the principle of extension of inequalities~(3.15.4), recall from the definition of sequential limit in~(3.13) that the functions given by
\[s(n)=\sum_{k=0}^n x_k\quad s(\infty)=\sum_{k=0}^{\infty}x_k\qquad\text{and}\qquad t(n)=\sum_{k=0}^n\norm{x_k}\quad t(\infty)=\sum_{k=0}^{\infty}\norm{x_k}\]
are \emph{continuous} on \(\N\union\{\infty\}=\Nex\subseteq\Rex\). By continuity of the norm, the composite function \(n\mapsto\norm{s(n)}\) is also continuous on~\(\Nex\). Now \(\norm{s(n)}\le t(n)\) for all \(n\in\N\) and \(\N\)~is dense in~\(\Nex\), hence \(\norm{s(\infty)}\le t(\infty)\) by~(3.15.4), as desired. Other applications of the principle of extension are similar.
\end{rmk}

\begin{rmk}
In~(5.3.4), \(\sum_{\alpha\in A}\norm{x_{\alpha}}=\sup\left\{\,\sum_{\alpha\in J}\norm{x_{\alpha}}\mid J\subseteq A\text{ finite}\,\right\}\) by~(5.3.1). This is implicit in the proof of~(5.3.5).
\end{rmk}

\begin{rmk}
In~(5.3.4), \(2\epsilon\)~can be replaced by~\(\epsilon\), since \(H\)~can be chosen for~\(\epsilon/2\).
\end{rmk}

\begin{rmk}
In the proof of~(5.3.4), to construct~\(H\), first fix a bijection \(\varphi:\N\to A\). Then \(\sum_{n=0}^{\infty}\norm{x_{\varphi(n)}}\) converges, so there exists~\(M\) such that for all \(n\ge m\ge M\), \(\sum_{k=m}^n\norm{x_{\varphi(k)}}\le\epsilon\) (5.2.1). Let \(H=\varphi[0,M)\). Then if \(K\subseteq A\) is finite with \(H\sect K=\emptyset\), \(\inv{\varphi}[K]\subseteq[M,\infty)\), so if \(N=\max\inv{\varphi}[K]\), then \(\sum_{\alpha\in K}\norm{x_{\alpha}}\le\sum_{k=M}^N\norm{x_k}\le\epsilon\). Also \(\norm{\sum_{\alpha\in A}x_{\alpha}-\sum_{\alpha\in H}x_{\alpha}}=\norm{\sum_{n=M}^{\infty}x_{\varphi(n)}}\le\sum_{n=M}^{\infty}\norm{x_{\varphi(n)}}\le\epsilon\) by (5.3.1)~and~(5.3.2). Finally, if \(L\)~is finite with \(H\subseteq L\subseteq A\), then \(L-H\)~is finite with \((L-H)\sect H=\emptyset\), so \(\norm{\sum_{\alpha\in H}x_{\alpha}-\sum_{\alpha\in L}x_{\alpha}}=\norm{\sum_{\alpha\in L-H}x_{\alpha}}\le\sum_{\alpha\in L-H}\norm{x_{\alpha}}\le\epsilon\), and it follows that \(\norm{\sum_{\alpha\in A}x_{\alpha}-\sum_{\alpha\in L}x_{\alpha}}\le 2\epsilon\).
\end{rmk}

\begin{rmk}
In the proof of~(5.3.6), the idea is to use finite approximations of finitely many of the~\(z_n\) to obtain a finite approximation of~\(\sum_{\alpha\in A}x_\alpha\).
\end{rmk}

% References
\begin{thebibliography}{0}
\bibitem{dieudonne} Dieudonn\'e, J. \textit{Foundations of Modern Analysis.} Academic Press, 1960.
\end{thebibliography}
\end{document}
